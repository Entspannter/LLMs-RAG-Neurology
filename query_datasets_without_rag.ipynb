{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_questions_dataset(file_path):\n",
    "    questions_dataframe = pd.read_excel(file_path)\n",
    "    questions = pd.DataFrame(questions_dataframe, columns=[\"Question Number\", \"Type\", \"Question\", \"Sample Answer According to Guideline\"])\n",
    "    questions[\"De Facto Answer\"] = \"\"\n",
    "    # add a batch number column \n",
    "    questions[\"batch\"] = 0\n",
    "    # duplicate the questions to have 4 batches in total and increase the batch number\n",
    "    questions = pd.concat([questions]*4)\n",
    "    questions[\"batch\"] = questions.groupby(\"Question\").cumcount()\n",
    "    questions.sort_values([\"Question Number\", \"batch\"], inplace=True)\n",
    "    questions = questions.reset_index(drop=True)\n",
    "    return questions\n",
    "\n",
    "questions = load_questions_dataset(\"questions.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "api_key= os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_gpt4(medical_question):\n",
    "    # Prepare the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-2024-04-09\",\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    # Extracting the response\n",
    "    full_response = response.choices[0].message.content.strip()\n",
    "\n",
    "    return full_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and expand the results into two new columns in the dataframe\n",
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_gpt4(x)).apply(pd.Series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "\n",
    "\n",
    "questions[\"Model\"] = \"GPT-4-Turbo\"\n",
    "questions.to_excel(\"Results/GPT4_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = load_questions_dataset(\"questions.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_gpt4o(medical_question):\n",
    "    # Prepare the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Use the newer API to send the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-11-20\",\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    # Extracting the response\n",
    "    full_response = response.choices[0].message.content.strip()\n",
    "\n",
    "    return full_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and expand the results into two new columns in the dataframe\n",
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_gpt4o(x)).apply(pd.Series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"GPT-4o\"\n",
    "\n",
    "questions.to_excel(\"Results/GPT4o_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = load_questions_dataset(\"questions.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_gpt4omini(medical_question):\n",
    "    # Prepare the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Use the newer API to send the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    # Extracting the response\n",
    "    full_response = response.choices[0].message.content.strip()\n",
    "\n",
    "    return full_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and expand the results into two new columns in the dataframe\n",
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_gpt4omini(x)).apply(pd.Series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"GPT-4o mini\"\n",
    "\n",
    "questions.to_excel(\"Results/GPT4omini_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.2,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = load_questions_dataset(\"questions.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def consult_with_gemini(medical_question):\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            [f\"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                    Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                        - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                        - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                        - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                        - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                        - Including citations to the guidelines or other reputable sources as needed.\n",
    "                    Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                    Ensure all relevant medical and scientific details are included to support your answer.\n",
    "                {medical_question}\"\"\"],\n",
    "            generation_config={\n",
    "                \"top_p\": 0.95,\n",
    "                \"temperature\": 0.2,\n",
    "            },\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        # Extracting and processing the generated text\n",
    "        text = response.text\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and expand the results into two new columns in the dataframe\n",
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_gemini(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"De Facto Answer\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"Gemini-1.5-Pro\"\n",
    "questions.to_excel(\"Results/Gemini_Pro_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = load_questions_dataset(\"questions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_llama(medical_question):\n",
    "    # Setup the API call to LLaMA\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ],\n",
    "        temperature=0.2,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    if completion.choices and completion.choices[0].message:\n",
    "        text = completion.choices[0].message.content.strip()\n",
    "\n",
    "        sleep(2.9)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_llama(x)).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"LLaMA3-70b-8192\"\n",
    "questions.to_excel(\"Results/LLaMA3_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIXTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = load_questions_dataset(\"questions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_mixtral(medical_question):\n",
    "    # Setup the API call to LLaMA\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ],\n",
    "        temperature=0.2,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    if completion.choices and completion.choices[0].message:\n",
    "        text = completion.choices[0].message.content.strip()\n",
    "\n",
    "        sleep(2.9)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_mixtral(x)).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"Mixtral-8x7b\"\n",
    "\n",
    "questions.to_excel(\"Results/Mixtral_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA NEMOTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key= os.getenv(\"NVIDIA_API_KEY\")\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = api_key\n",
    ")\n",
    "questions = load_questions_dataset(\"questions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_llama_nemotron(medical_question):\n",
    "    # Prepare the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Use the newer API to send the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        top_p=1,\n",
    "        max_tokens=1024,\n",
    "        stream=False,\n",
    "  )\n",
    "    \n",
    "    # Extracting the response\n",
    "    full_response = response.choices[0].message.content.strip()\n",
    "\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_llama_nemotron(x)).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"Llama-3.1-nemotron-70b\"\n",
    "\n",
    "questions.to_excel(\"Results/Llama_Nemotron_RAW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key= os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "client = OpenAI(\n",
    "  base_url = \"https://api.perplexity.ai\",\n",
    "  api_key = api_key\n",
    ")\n",
    "questions = load_questions_dataset(\"questions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_with_perplexity_llama(medical_question):\n",
    "    # Prepare the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a dedicated AI medical assistant specializing in neurology. Your answers should be based on medical guidelines such as the most recent AAN guidelines and are strictly truthful. If the information is not available in guidelines, state it clearly. Refrain from including irrelevant or out-of-context details.\n",
    "                Please respond to the following question using information from guidelines. Focus on providing answers that are:\n",
    "                    - Directly linked to the guidelines, citing specific sections or page numbers when possible. Make sure to mention the guidelines you are referencing and the source.\n",
    "                    - Presented in concise bullet points. Do not bloat the answer unnecessarily. Keep it short and professional.\n",
    "                    - Comprehensive, including all relevant details about disease type, disease stage, patient age, and clinical trials when applicable.\n",
    "                    - Honest, clearly stating if the information is not covered in the guidelines.\n",
    "                    - Including citations to the guidelines or other reputable sources as needed.\n",
    "                Based on guidelines such as the most recent AAN guidelines, provide a detailed and truthful response that addresses the specifics of the question.\n",
    "                Ensure all relevant medical and scientific details are included to support your answer.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": medical_question\n",
    "        }\n",
    "    ]\n",
    "    try:\n",
    "    # Use the newer API to send the prompt\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.1-sonar-huge-128k-online\",\n",
    "            messages=messages,\n",
    "            temperature=0.2,\n",
    "            top_p=0.9,\n",
    "            max_tokens=1024,\n",
    "            stream=False,\n",
    "    )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        # Extracting the response\n",
    "        full_response = response.choices[0].message.content.strip()\n",
    "    except:\n",
    "        try:\n",
    "            full_response = response.choices[0].message.content\n",
    "        except:\n",
    "            full_response = response\n",
    "\n",
    "\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[['De Facto Answer']] = questions['Question'].apply(lambda x: consult_with_perplexity_llama(x)).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"Rater 1\"] = \"\"\n",
    "questions[\"Rater 2\"] = \"\"\n",
    "questions[\"Final Rating\"] = \"\"\n",
    "questions[\"Source\"] = \"\"\n",
    "questions[\"Model\"] = \"Llama-3.1-sonar-405b-online\"\n",
    "\n",
    "questions.to_excel(\"Results/Llama_huge_Perplexity.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
